2024-01-19 18:36:11.986130: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-19 18:36:13.082790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Namespace(Fusion_method='weightedfeature_mean', Nsample=10000, adaptive_contrastive_weight=True, batch=2000, clip_norm=5.0, contrastive_similarity='cos', data_file='../dataset1/10x_PBMC/', ddc_direct=True, ddc_hidden=32, ddcuse_bn=False, delta=0.01, device='cuda:2', epochs1=600, epochs2=750, funcs='contrastiveloss|SelfEntropy|ddcs', highly_genes=2000, latent_projector_config=False, learning_rate=1e-05, lr=5e-05, lr1=1e-05, model_file='AE_weights_1.pth.tar', n1=64, n2=128, n3=1024, n4=10000, n5=10000, n_clusters=19, n_views=2, negative_samples_ratio=-1, projector_config=False, rel_sigma=0.1, scheduler_gamma=0.1, scheduler_step_size=None, seed=3407, sigma=0.1, sigma1=1.5, sigma2=1.5, tau=0.1, weights=None)
2.0.1+cu117
----------shape of data------------------
(9631, 29095)
(9631, 107194)
9631
------------------------------------
(9631, 2000)
AnnData object with n_obs × n_vars = 9631 × 2000
    obs: 'domain', 'protocol', 'dataset', 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_ATAC', 'nFeature_ATAC', 'nCount_SCT', 'nFeature_SCT', 'SCT.weight', 'ATAC.weight', 'wsnn_res.0.8', 'seurat_clusters', 'sub.cluster', 'cell_type', 'Group', 'n_counts', 'size_factors'
    var: 'gene_ids', 'feature_types', 'genome', 'chrom', 'chromStart', 'chromEnd', 'name', 'score', 'strand', 'thickStart', 'thickEnd', 'itemRgb', 'blockCount', 'blockSizes', 'blockStarts', 'gene_type', 'gene_name', 'hgnc_id', 'havana_gene', 'tag', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'dispersions', 'dispersions_norm'
    uns: 'hvg', 'log1p'
(9631, 2000)
AnnData object with n_obs × n_vars = 9631 × 2000
    obs: 'domain', 'protocol', 'dataset', 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_ATAC', 'nFeature_ATAC', 'nCount_SCT', 'nFeature_SCT', 'SCT.weight', 'ATAC.weight', 'wsnn_res.0.8', 'seurat_clusters', 'sub.cluster', 'cell_type', 'Group', 'n_counts', 'size_factors'
    var: 'feature_types', 'genome', 'chrom', 'chromStart', 'chromEnd', 'n_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'
    uns: 'log1p', 'hvg'
-------len(y)----------------
19
/home/zhoubenjie/model_11_16/graph_funcion.py:73: RuntimeWarning: divide by zero encountered in log
  PPMI = np.log(np.divide(np.multiply(D, A), np.dot(row_sum, col_sum)))
/home/zhoubenjie/model_11_16/graph_funcion.py:73: RuntimeWarning: divide by zero encountered in log
  PPMI = np.log(np.divide(np.multiply(D, A), np.dot(row_sum, col_sum)))
pre_train_loss_2:
10   0.2485617995262146
pre_train_loss_1:
10   0.5240255123132045   0.1936313956975937  7.874470708306375  0.251649409532547
pre_train_loss_2:
20   0.24997487664222717
pre_train_loss_1:
20   0.5208952940570765   0.19341418147087097  7.716461192244818  0.2503165006637573
pre_train_loss_2:
30   0.25236496329307556
pre_train_loss_1:
30   0.5194401278309793   0.19317783415317535  7.839271641897853  0.2478695809841156
pre_train_loss_2:
40   0.2530052661895752
pre_train_loss_1:
40   0.5174633564652672   0.19292548298835754  7.756926140205765  0.246968612074852
pre_train_loss_2:
50   0.25408658385276794
pre_train_loss_1:
50   0.5147061051352435   0.1926630437374115  7.6348133526604745  0.24569493532180786
pre_train_loss_2:
60   0.255648672580719
pre_train_loss_1:
60   0.5142067843618265   0.1923804134130478  7.732516392491977  0.24450120329856873
pre_train_loss_2:
70   0.25657594203948975
pre_train_loss_1:
70   0.5111780494283301   0.19205057621002197  7.582313491211954  0.24330434203147888
pre_train_loss_2:
80   0.2581292986869812
pre_train_loss_1:
80   0.5100491657388742   0.191682830452919  7.6173530472570175  0.242192804813385
pre_train_loss_2:
90   0.2596516013145447
pre_train_loss_1:
90   0.5086129164467483   0.1912674754858017  7.665938568812901  0.2406860589981079
pre_train_loss_2:
100   0.2603529095649719
pre_train_loss_1:
100   0.5069761210752053   0.19084149599075317  7.632141277914467  0.2398132085800171
pre_train_loss_2:
110   0.26243942975997925
pre_train_loss_1:
110   0.5050528131945191   0.1902649700641632  7.566800793243032  0.23911982774734497
pre_train_loss_2:
120   0.26249176263809204
pre_train_loss_1:
120   0.502474015358048   0.1895204782485962  7.589049056466152  0.23706305027008057
pre_train_loss_2:
130   0.2638610005378723
pre_train_loss_1:
130   0.5000839092587666   0.18882249295711517  7.4879166558904995  0.23638224601745605
pre_train_loss_2:
140   0.2647517919540405
pre_train_loss_1:
140   0.4991626614938328   0.18785274028778076  7.581018900972106  0.23549973964691162
pre_train_loss_2:
150   0.26610952615737915
pre_train_loss_1:
150   0.4982151018765749   0.18684712052345276  7.609288416178837  0.23527508974075317
pre_train_loss_2:
160   0.26649922132492065
pre_train_loss_1:
160   0.495603618599781   0.18561440706253052  7.565716040910149  0.23433205485343933
pre_train_loss_2:
170   0.26650476455688477
pre_train_loss_1:
170   0.4940817495040372   0.18412017822265625  7.620351660770922  0.23375806212425232
pre_train_loss_2:
180   0.2674749195575714
pre_train_loss_1:
180   0.4921206618109957   0.18269774317741394  7.60664204517618  0.2333565056324005
pre_train_loss_2:
190   0.26793575286865234
pre_train_loss_1:
190   0.4887963047640862   0.1804659515619278  7.528033465319295  0.23305001854896545
pre_train_loss_2:
200   0.2681517004966736
pre_train_loss_1:
200   0.4874775244511882   0.1784760057926178  7.632016228812132  0.23268136382102966
pre_train_loss_2:
210   0.2689252197742462
pre_train_loss_1:
210   0.4841543436560755   0.17569208145141602  7.605826487280182  0.23240399360656738
pre_train_loss_2:
220   0.2692611813545227
pre_train_loss_1:
220   0.4795980686276356   0.17230618000030518  7.569597754172479  0.23159590363502502
pre_train_loss_2:
230   0.26964831352233887
pre_train_loss_1:
230   0.4770899961183844   0.1689792424440384  7.621190570695974  0.23189884424209595
pre_train_loss_2:
240   0.26922106742858887
pre_train_loss_1:
240   0.47443754040146513   0.16480965912342072  7.81033504798476  0.2315245270729065
pre_train_loss_2:
250   0.26979541778564453
pre_train_loss_1:
250   0.46871495512940686   0.160223126411438  7.686056462743086  0.23163126409053802
pre_train_loss_2:
260   0.2698141038417816
pre_train_loss_1:
260   0.4645557534433612   0.15523386001586914  7.796799210083574  0.23135389387607574
pre_train_loss_2:
270   0.26959097385406494
pre_train_loss_1:
270   0.4591505787327376   0.14951379597187042  7.840076079512509  0.2312360256910324
pre_train_loss_2:
280   0.26917123794555664
pre_train_loss_1:
280   0.4528371432711683   0.14308097958564758  7.796566951175556  0.23179049789905548
pre_train_loss_2:
290   0.26910191774368286
pre_train_loss_1:
290   0.4463696349331474   0.13642805814743042  7.80828241178131  0.2318587601184845
pre_train_loss_2:
300   0.26864326000213623
pre_train_loss_1:
300   0.43766742379518964   0.1289086937904358  7.701122195574261  0.23174750804901123
pre_train_loss_2:
310   0.2686729431152344
pre_train_loss_1:
310   0.4321590690095886   0.12198843061923981  7.806162817077482  0.23210901021957397
pre_train_loss_2:
320   0.268212229013443
pre_train_loss_1:
320   0.42532252582034646   0.11306118965148926  7.9444688430638895  0.2328166514635086
pre_train_loss_2:
330   0.26760226488113403
pre_train_loss_1:
330   0.41668832540698436   0.1058623194694519  7.75251002628365  0.23330090939998627
pre_train_loss_2:
340   0.2672654390335083
pre_train_loss_1:
340   0.41427504653004277   0.09648436307907104  8.429034808543792  0.23350033164024353
pre_train_loss_2:
350   0.26678287982940674
pre_train_loss_1:
350   0.4013716182997147   0.08911101520061493  7.799617344044842  0.23426443338394165
pre_train_loss_2:
360   0.2661125063896179
pre_train_loss_1:
360   0.3955036870609202   0.08135593682527542  7.9279432393161295  0.23486831784248352
pre_train_loss_2:
370   0.26503098011016846
pre_train_loss_1:
370   0.38910025013761596   0.07380672544240952  7.956852605717261  0.23572500050067902
pre_train_loss_2:
380   0.26419419050216675
pre_train_loss_1:
380   0.3816747428170192   0.06672902405261993  7.873254318449376  0.23621317744255066
pre_train_loss_2:
390   0.2634349465370178
pre_train_loss_1:
390   0.3771255517551957   0.060063548386096954  7.997970266140086  0.23708230257034302
pre_train_loss_2:
400   0.26258981227874756
pre_train_loss_1:
400   0.3712732717306773   0.05436350032687187  7.899011298133535  0.2379196584224701
pre_train_loss_2:
410   0.2615518271923065
pre_train_loss_1:
410   0.36549550829945615   0.04923047870397568  7.834232947348167  0.23792269825935364
pre_train_loss_2:
420   0.26093217730522156
pre_train_loss_1:
420   0.36446979833502613   0.0438782274723053  8.080932689566453  0.23978224396705627
pre_train_loss_2:
430   0.2600643038749695
pre_train_loss_1:
430   0.3618539609177397   0.03973613679409027  8.107997664943197  0.24103784561157227
pre_train_loss_2:
440   0.258787602186203
pre_train_loss_1:
440   0.35961580576238034   0.03563498705625534  8.227110767599939  0.24170970916748047
pre_train_loss_2:
450   0.2581693232059479
pre_train_loss_1:
450   0.35553365693166394   0.032256580889225006  8.008037906810184  0.24319669604301453
pre_train_loss_2:
460   0.25707370042800903
pre_train_loss_1:
460   0.3543870761897878   0.029535401612520218  8.1564647695096  0.24328702688217163
pre_train_loss_2:
470   0.25618618726730347
pre_train_loss_1:
470   0.35197403652318504   0.026479266583919525  8.14887014935234  0.24400606751441956
pre_train_loss_2:
480   0.255331814289093
pre_train_loss_1:
480   0.3489028400867656   0.02367929369211197  7.988063517356663  0.2453429102897644
pre_train_loss_2:
490   0.25430405139923096
pre_train_loss_1:
490   0.35068192858992686   0.021129362285137177  8.349487804620138  0.2460576891899109
pre_train_loss_2:
500   0.25387126207351685
pre_train_loss_1:
500   0.34873833381784125   0.019672038033604622  8.218734399628804  0.2468789517879486
pre_train_loss_2:
510   0.2528056800365448
pre_train_loss_1:
510   0.34538912054374915   0.017441395670175552  8.056992691233855  0.24737779796123505
pre_train_loss_2:
520   0.25176844000816345
pre_train_loss_1:
520   0.34604129491595564   0.016502056270837784  8.126017468271789  0.24827906489372253
pre_train_loss_2:
530   0.25160014629364014
pre_train_loss_1:
530   0.34451763561599885   0.01510615274310112  8.047326557942664  0.24893821775913239
pre_train_loss_2:
540   0.25045597553253174
pre_train_loss_1:
540   0.3440126579013464   0.0136265829205513  8.03031653855738  0.25008291006088257
pre_train_loss_2:
550   0.24926336109638214
pre_train_loss_1:
550   0.34104118176135484   0.01235564798116684  7.795427373009984  0.2507312595844269
pre_train_loss_2:
560   0.24896281957626343
pre_train_loss_1:
560   0.34084245542001923   0.01134268008172512  7.828884737503726  0.25121092796325684
pre_train_loss_2:
570   0.2497844099998474
pre_train_loss_1:
570   0.34035393508286194   0.010686129331588745  7.791444571823789  0.2517533600330353
pre_train_loss_2:
580   0.24852289259433746
pre_train_loss_1:
580   0.34427325348263726   0.009743381291627884  8.23344249733363  0.25219544768333435
pre_train_loss_2:
590   0.2479572892189026
pre_train_loss_1:
590   0.34197529618578615   0.009307649917900562  8.066516862201155  0.252002477645874
pre_train_loss_2:
600   0.2476639747619629
pre_train_loss_1:
600   0.33847911659990754   0.008567511104047298  7.6990918064390685  0.2529206871986389
/home/zhoubenjie/anaconda3/envs/New/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:247: UserWarning: Array is not symmetric, and will be converted to symmetric by average with its transpose.
  adjacency = check_symmetric(adjacency)
------kmeans---
0.7475199831891828 0.528826527641116
------spectral-
0.7760257070202113 0.578450508246926
/home/zhoubenjie/anaconda3/envs/New/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:247: UserWarning: Array is not symmetric, and will be converted to symmetric by average with its transpose.
  adjacency = check_symmetric(adjacency)
------kmeans---
0.6859182762375322 0.44989223548316126
------spectral-
0.7543868504589484 0.6018996813653227
NMI1: 0.7760, ARI1: 0.5785,
NMI2: 0.7544, ARI2: 0.6019,
pre_train over
-------------train start--------------------
alt_train_loss_clus:
10   0.371452924401932   0.0038839870830997825  8.327026067065498  -1.890410304069519  0.2587948441505432
alt_train_loss_tran:
10   1.491793700411698   0.003963690949603915  8.558872799553553  0.06431726785376668  30.640399528432983  tensor(14.4679, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
10   0.24277572333812714
alt_train_loss_clus:
20   0.3607396945855469   0.001968868018593639  8.655148060385887  -1.9001524448394775  0.2640002965927124
alt_train_loss_tran:
20   1.2246205570513626   0.001976909232325852  9.779312008640382  0.04486283048754558  31.626019065205952  tensor(13.1686, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
20   0.23661398887634277
alt_train_loss_clus:
30   0.3610113997465486   0.0010598498047329485  9.098994484977078  -1.9096436500549316  0.26897117495536804
alt_train_loss_tran:
30   0.9575748802120003   0.0009339573443867266  8.511845790354046  0.026300358003936708  32.77108579549568  tensor(12.0023, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
30   0.2327602505683899
alt_train_loss_clus:
40   0.35328953656274803   0.0005423024413175881  8.438209922891089  -1.9174110889434814  0.2730714678764343
alt_train_loss_tran:
40   0.7801287417780658   0.0005746306997025385  9.232511804588636  0.014741926584974863  33.134521854921594  tensor(10.6928, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
40   0.22959065437316895
alt_train_loss_clus:
50   0.3663574333679296   0.00037672485632356256  9.763045258860958  -1.9241732358932495  0.27458059787750244
alt_train_loss_tran:
50   0.6809220726555578   0.000396502400690224  9.509840297516362  0.008905620277801063  32.405538136347445  tensor(9.8560, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
50   0.22763997316360474
alt_train_loss_clus:
60   0.3540641525764413   0.00030775779305258766  8.358354377601517  -1.9297254085540771  0.2770516574382782
alt_train_loss_tran:
60   0.6166382118311002   0.00028954940353287384  8.683240670442942  0.005242357165116118  29.71501470524061  tensor(9.4897, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
60   0.22647306323051453
alt_train_loss_clus:
70   0.35520969343759823   0.000255391831160523  8.387177368548471  -1.933416724205017  0.2784510850906372
alt_train_loss_tran:
70   0.5826033400543462   0.00023163896548794582  9.100586436660581  0.0034161239127570298  30.167003760374367  tensor(9.1024, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
70   0.22530531883239746
alt_train_loss_clus:
80   0.35746602363236135   0.00019382713799132034  8.573164719439928  -1.9377110004425049  0.27948465943336487
alt_train_loss_tran:
80   0.5503352235551384   0.00019704365695361048  8.577229247164638  0.00228523130499525  32.01843335797554  tensor(8.7948, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
80   0.22487859427928925
alt_train_loss_clus:
90   0.35289361057591817   0.00016311351282638498  8.069857213202127  -1.9403095245361328  0.2802654504776001
alt_train_loss_tran:
90   0.5355155787256268   0.00016953173690126278  8.543232768717704  0.0017148120368801756  26.41057453667619  tensor(8.6248, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
90   0.22401593625545502
alt_train_loss_clus:
100   0.354151648456073   0.0001398569183947984  8.057177970612477  -1.9423192739486694  0.28189289569854736
alt_train_loss_tran:
100   0.5186580300550201   0.0001570903004903812  7.901927616775417  0.0013982740410938277  25.871586035285137  tensor(8.4817, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
100   0.22330820560455322
alt_train_loss_clus:
110   0.3580891173940455   0.00012443838932085782  8.204041797107323  -1.9431428909301758  0.2845200300216675
alt_train_loss_tran:
110   0.5065884027725245   0.00013631044930662028  8.032717491811331  0.0010131900908163516  22.60213351631505  tensor(8.2953, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
110   0.22143781185150146
alt_train_loss_clus:
120   0.3610091083325826   0.00013367412975640036  8.394136593480669  -1.94392728805542  0.28545063734054565
alt_train_loss_tran:
120   0.4979270376131137   0.00010791367822093889  8.143889253522158  0.0007261762866619392  20.196107624758696  tensor(8.1629, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
120   0.22065022587776184
alt_train_loss_clus:
130   0.3633645713486292   0.00011032449219783302  8.370925802561016  -1.9442591667175293  0.2882733643054962
alt_train_loss_tran:
130   0.4951571168008254   0.00010446186570334248  8.47108175826602  0.000656073817935976  23.855965998077714  tensor(8.0568, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
130   0.22103264927864075
alt_train_loss_clus:
140   0.3600012974475547   9.44508756219875e-05  8.10102356608994  -1.944505214691162  0.287769079208374
alt_train_loss_tran:
140   0.4868814543882488   8.642394277558196e-05  7.9530873307130365  0.0005224207361607114  19.462265917785246  tensor(8.0252, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
140   0.22010114789009094
alt_train_loss_clus:
150   0.358824591484593   8.182744932128116e-05  7.966138778763984  -1.9446313381195068  0.28806808590888977
alt_train_loss_tran:
150   0.48157664905151887   9.518523802398704e-05  8.244423074715723  0.0004952541817146994  18.33209957217683  tensor(7.8646, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
150   0.22000885009765625
alt_train_loss_clus:
160   0.36474355002386494   8.754604277783073e-05  8.406504916596226  -1.9446367025375366  0.28952622413635254
alt_train_loss_tran:
160   0.4738059754258243   8.897569568944164e-05  7.824374124397174  0.00045245826095197117  16.124040880920003  tensor(7.8030, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
160   0.21962563693523407
alt_train_loss_clus:
170   0.36340374206628956   8.423531289736275e-05  8.406630447570542  -1.944724440574646  0.2882187068462372
alt_train_loss_tran:
170   0.46945534903903496   7.614796413690783e-05  8.11886553038308  0.00035086976504317136  16.017587841806304  tensor(7.6799, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
170   0.2204260528087616
alt_train_loss_clus:
180   0.359090774539208   7.963604912220035e-05  8.348444447706168  -1.9448134899139404  0.2845340371131897
alt_train_loss_tran:
180   0.46810058373320645   7.442540663760155e-05  7.882234396983549  0.00033969939568123664  14.892442615586434  tensor(7.7027, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
180   0.22117534279823303
alt_train_loss_clus:
190   0.3543195850984322   7.34837849449832e-05  7.9942378641584675  -1.9449100494384766  0.2833669185638428
alt_train_loss_tran:
190   0.457134999434822   7.17875864211237e-05  7.940451703867617  0.00027012486907551647  14.172245415976043  tensor(7.4862, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
190   0.22248998284339905
alt_train_loss_clus:
200   0.3524432640830828   7.587395157315768e-05  7.853926984414739  -1.9449957609176636  0.28287023305892944
alt_train_loss_tran:
200   0.4446200326252229   7.136392741813324e-05  7.790754578088771  0.00025427474838579656  13.835584080283535  tensor(7.2691, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
200   0.2242470681667328
alt_train_loss_clus:
210   0.355257555898188   6.622054388571996e-05  8.34799123816447  -1.944997787475586  0.2808404266834259
alt_train_loss_tran:
210   0.446034804860736   6.686322740279138e-05  7.880038633191212  0.0002360634371143533  13.5365216680166  tensor(7.2841, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
210   0.227286696434021
alt_train_loss_clus:
220   0.35202714498886245   6.357641359500121e-05  8.062207161132584  -1.944944977760315  0.2804940342903137
alt_train_loss_tran:
220   0.45005401022754776   6.567260425072163e-05  7.758284593038076  0.0002194740804952744  15.574895988650919  tensor(7.3924, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
220   0.22776047885417938
alt_train_loss_clus:
230   0.34971728870586977   6.515776658488903e-05  7.978999919432701  -1.9451048374176025  0.27900123596191406
alt_train_loss_tran:
230   0.429003471559828   6.162111276353244e-05  7.949186757860064  0.00019403318992772256  15.37343282029256  tensor(6.9391, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
230   0.2283479869365692
alt_train_loss_clus:
240   0.34750486181661366   5.477540798892733e-05  7.809580090184571  -1.945063829421997  0.27858662605285645
alt_train_loss_tran:
240   0.41129904403139783   5.9739037169492804e-05  7.966275422011213  0.00019795966591118486  13.091815410089652  tensor(6.5812, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
240   0.22838658094406128
alt_train_loss_clus:
250   0.34828281162251223   5.9236246670479886e-05  7.910527947885422  -1.9450676441192627  0.27831050753593445
alt_train_loss_tran:
250   0.40812490467584495   5.613816392724402e-05  7.999499517251307  0.00015138653770918609  12.43905214530368  tensor(6.5211, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
250   0.22966241836547852
alt_train_loss_clus:
260   0.34254912823140937   6.27260760666104e-05  7.735656356723361  -1.945218563079834  0.27429139614105225
alt_train_loss_tran:
260   0.43034475466271094   5.992198202875443e-05  7.801798670703706  0.0001471015684728627  12.479874888455369  tensor(7.0051, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
260   0.23103168606758118
alt_train_loss_clus:
270   0.34386555021225607   5.831708222103771e-05  8.021568710861859  -1.945117473602295  0.2727922797203064
alt_train_loss_tran:
270   0.4353315661813639   6.310536446108017e-05  7.919298860574321  0.00017656695627010777  10.705655826380438  tensor(7.0748, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
270   0.23365482687950134
alt_train_loss_clus:
280   0.33853799325948636   6.45654508844018e-05  7.639927708147148  -1.9453575611114502  0.2712198495864868
alt_train_loss_tran:
280   0.4193043152805802   6.88214749970939e-05  7.585433259341864  0.0001743627612995624  12.017121212451745  tensor(6.8204, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
280   0.23535943031311035
alt_train_loss_clus:
290   0.33976264668068434   5.916733425692655e-05  7.903946709608242  -1.945239782333374  0.2698577046394348
alt_train_loss_tran:
290   0.4198135636590259   6.619629493798129e-05  7.700436113116572  0.00014030124611963402  10.51290843054718  tensor(6.8149, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
290   0.23565025627613068
alt_train_loss_clus:
300   0.3376543453946744   5.3700647185905837e-05  7.596654109014542  -1.9454855918884277  0.27087822556495667
alt_train_loss_tran:
300   0.4175924575610626   5.6789856898831204e-05  7.836716354717661  0.00011589988025662024  11.274793758176358  tensor(6.7500, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
300   0.23345734179019928
nmi:  0.6674450649440471
ari:  0.4790592023501174
alt_train_loss_clus:
310   0.3354598748359887   5.8052772146766074e-05  7.597874290736508  -1.945527195930481  0.26862823963165283
alt_train_loss_tran:
310   0.4190082877425108   5.2325864089652896e-05  7.777465642302799  0.00011634538259386318  10.878784398214318  tensor(6.7909, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
310   0.23583486676216125
nmi:  0.6616002110163146
ari:  0.45660985121548264
alt_train_loss_clus:
320   0.33802487915587315   6.04233136982657e-05  7.6710546321428215  -1.9455890655517578  0.2704380452632904
alt_train_loss_tran:
320   0.4243937722102745   5.014951602788642e-05  7.91353045323521  8.552489089197479e-05  11.289612868245722  tensor(6.8780, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
320   0.2356024533510208
nmi:  0.6541056465899354
ari:  0.45760084963529374
alt_train_loss_clus:
330   0.3406603852562362   6.283645780058578e-05  7.901014864172209  -1.9456408023834229  0.2707500755786896
alt_train_loss_tran:
330   0.40291240290161434   5.319673437043093e-05  7.75045621971854  9.946048521669582e-05  10.049282667553458  tensor(6.4776, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
330   0.23356522619724274
nmi:  0.6768775615510066
ari:  0.5032600934511423
alt_train_loss_clus:
340   0.3425035871811768   5.527559551410377e-05  8.171624340020102  -1.9456816911697388  0.26996299624443054
alt_train_loss_tran:
340   0.41332461294324163   6.238105197553523e-05  7.998563886313491  0.0001018325428958633  11.123396893562287  tensor(6.6339, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
340   0.2355271279811859
nmi:  0.674293603304338
ari:  0.4991130732903376
alt_train_loss_clus:
350   0.33570884068578805   6.109931382525247e-05  7.749832518422834  -1.945664644241333  0.26732784509658813
alt_train_loss_tran:
350   0.37595756095743443   5.683632116415538e-05  7.825762907941998  9.689038006399642e-05  10.79648326727511  tensor(5.9233, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
350   0.23977014422416687
nmi:  0.7080267978105149
ari:  0.5705182002298763
alt_train_loss_clus:
360   0.3351859530557226   5.8663041272666305e-05  7.662636509116732  -1.9457814693450928  0.2677018642425537
alt_train_loss_tran:
360   0.3908850297975075   6.178456533234566e-05  7.766024194454776  9.777064406080171e-05  10.568789503358918  tensor(6.2326, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
360   0.23927298188209534
nmi:  0.7082030855810062
ari:  0.5717594256575051
alt_train_loss_clus:
370   0.3355028563667961   6.355352161335759e-05  7.741916106838609  -1.9458128213882446  0.2671772241592407
alt_train_loss_tran:
370   0.3964511292161504   5.588371277553961e-05  7.74369533702  8.298458624267369e-05  10.89980220716766  tensor(6.3525, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
370   0.23759785294532776
nmi:  0.7332067068644973
ari:  0.6128951810014736
alt_train_loss_clus:
380   0.3332182539460554   5.948490615992341e-05  7.723437108589124  -1.9457998275756836  0.2651180326938629
alt_train_loss_tran:
380   0.39698899959730943   5.729347867600154e-05  7.7541067931091225  8.96882988854486e-05  9.889889901095476  tensor(6.3596, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
380   0.23582428693771362
nmi:  0.7412801548208965
ari:  0.6242434189473081
alt_train_loss_clus:
390   0.33316280384020447   5.567631706071552e-05  7.508692495754019  -1.9459983110427856  0.26724910736083984
alt_train_loss_tran:
390   0.4009703196118718   5.515212251339108e-05  7.705384100546516  8.145414176397026e-05  10.036717707328615  tensor(6.4510, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
390   0.23870249092578888
nmi:  0.7388091214506184
ari:  0.6268387236132416
alt_train_loss_clus:
400   0.33113831022090573   5.520625018107239e-05  7.545948832738043  -1.9460530281066895  0.2648570239543915
alt_train_loss_tran:
400   0.3881449436920062   4.9708039114193525e-05  7.7600939068198915  7.183979641922633e-05  9.150900489938945  tensor(6.1866, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
400   0.23751486837863922
nmi:  0.7359890160504324
ari:  0.6257857789832583
alt_train_loss_clus:
410   0.3322983146404746   4.9740639042283874e-05  7.546626538311979  -1.9460359811782837  0.2660648226737976
alt_train_loss_tran:
410   0.3854659027091215   4.803318370250054e-05  8.08356917949381  6.772707502022968e-05  9.774152836390654  tensor(6.0695, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
410   0.2379836142063141
nmi:  0.7364590460918417
ari:  0.6315426439322168
alt_train_loss_clus:
420   0.3340740980018755   4.663480831368361e-05  7.541583003680088  -1.9460368156433105  0.2679221034049988
alt_train_loss_tran:
420   0.3791824374958432   4.5099745875631925e-05  7.963746729649383  7.203033464975306e-05  9.451145078669244  tensor(5.9675, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
420   0.23691226541996002
nmi:  0.7349318601508025
ari:  0.6541537626451661
alt_train_loss_clus:
430   0.3326742625056468   3.883326280629262e-05  7.7001220952992355  -1.9461071491241455  0.26501524448394775
alt_train_loss_tran:
430   0.38646804688140945   5.079021957499208e-05  7.869270819172927  5.1558923132688506e-05  8.704467434692337  tensor(6.1350, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
430   0.23621107637882233
nmi:  0.7292784096745262
ari:  0.6301313757393165
alt_train_loss_clus:
440   0.3325884481208796   4.120339417568175e-05  7.636065859413256  -1.9462265968322754  0.26554688811302185
alt_train_loss_tran:
440   0.39186970247993125   4.8754112867754884e-05  7.455616026145985  6.0565798776224256e-05  9.458000993573435  tensor(6.3244, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
440   0.2386435717344284
nmi:  0.7442022978340396
ari:  0.690165143579728
alt_train_loss_clus:
450   0.32977591288597863   3.939966973121045e-05  7.621168482963073  -1.9461613893508911  0.26290103793144226
alt_train_loss_tran:
450   0.3911657382401118   4.59409866380156e-05  7.56682703855277  4.9573465730645694e-05  8.728036175877723  tensor(6.2908, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
450   0.2363431304693222
nmi:  0.7484623290481621
ari:  0.700455620636254
alt_train_loss_clus:
460   0.331065867284443   3.790414302784484e-05  7.789767959820079  -1.9462454319000244  0.26252037286758423
alt_train_loss_tran:
460   0.38627269217446236   3.957029548473656e-05  7.6525944250680284  4.760504452860914e-05  9.424329872448606  tensor(6.1775, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
460   0.2370765209197998
nmi:  0.7474211218753815
ari:  0.6960111692908051
alt_train_loss_clus:
470   0.3280231406898729   4.130324032303179e-05  7.626929340778407  -1.9461674690246582  0.26107165217399597
alt_train_loss_tran:
470   0.3654899353041929   3.997971816716017e-05  7.667038064942792  4.36012137470243e-05  8.695168655000693  tensor(5.7597, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
470   0.23947957158088684
nmi:  0.7430154402734731
ari:  0.6708364618323169
alt_train_loss_clus:
480   0.33103287789677677   4.406030893733259e-05  7.64528337382752  -1.9462847709655762  0.26387086510658264
alt_train_loss_tran:
480   0.39916276674066503   4.1622714888944756e-05  7.672674134901206  4.571206409309525e-05  9.302796574321235  tensor(6.4313, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
480   0.24234464764595032
nmi:  0.731351351614426
ari:  0.6731244478547111
alt_train_loss_clus:
490   0.33046922923156036   3.7446344322233927e-05  7.510105140888573  -1.9462988376617432  0.2647252082824707
alt_train_loss_tran:
490   0.38572438628185296   4.148737616560538e-05  7.788704414056951  3.689917912197416e-05  9.269425151071172  tensor(6.1411, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
490   0.24052982032299042
nmi:  0.7290729586743667
ari:  0.6466378210319446
alt_train_loss_clus:
500   0.33045201183489015   3.922972155123716e-05  7.600182016397782  -1.9463638067245483  0.26378971338272095
alt_train_loss_tran:
500   0.37206112167801797   3.410071303733275e-05  7.618234389188908  3.2177653338294476e-05  8.736154132068961  tensor(5.9043, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
500   0.23896515369415283
nmi:  0.7239989555401073
ari:  0.6311438941302306
alt_train_loss_clus:
510   0.3261126753238538   4.32782339885307e-05  7.66657742967406  -1.9463282823562622  0.2587457597255707
alt_train_loss_tran:
510   0.37701062836667676   3.919076880265493e-05  7.534163117479453  4.362646586741903e-05  9.170253885893306  tensor(6.0168, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
510   0.24334369599819183
nmi:  0.7324251998267939
ari:  0.6305547694548864
alt_train_loss_clus:
520   0.3274803067154478   3.3808293665060773e-05  7.553693098933381  -1.9464094638824463  0.2613373398780823
alt_train_loss_tran:
520   0.36908316759179643   3.443459672780591e-05  7.598388273579831  3.114548280791496e-05  8.386801741496344  tensor(5.8489, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
520   0.24097944796085358
nmi:  0.7439371625208875
ari:  0.6704526242926613
alt_train_loss_clus:
530   0.32695674844898515   3.990283539678785e-05  7.53298616032151  -1.9463294744491577  0.2609595060348511
alt_train_loss_tran:
530   0.3760855845739693   3.852666395687265e-05  7.505411073544884  2.871368860724033e-05  8.242896295086199  tensor(6.0072, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
530   0.24153007566928864
nmi:  0.740168786521834
ari:  0.6671100035240708
alt_train_loss_clus:
540   0.327323076415505   3.540025500115007e-05  7.536684234060881  -1.9464495182037354  0.26133447885513306
alt_train_loss_tran:
540   0.36726553552052943   3.458719629634288e-05  7.440927163606983  2.5010273930092808e-05  8.869588274147183  tensor(5.8452, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
540   0.24221037328243256
nmi:  0.738241380046029
ari:  0.6743279733055823
alt_train_loss_clus:
550   0.3261495418241639   3.4379458156763576e-05  7.613842125418438  -1.9463640451431274  0.2593991458415985
alt_train_loss_tran:
550   0.3839977765265732   3.204336007911479e-05  7.443017696559505  2.439916534058284e-05  8.807827525205713  tensor(6.1801, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
550   0.24274319410324097
nmi:  0.754233300955144
ari:  0.7186592408931626
alt_train_loss_clus:
560   0.32282488147542   3.9252812712220475e-05  7.406191546545717  -1.9462766647338867  0.25810182094573975
alt_train_loss_tran:
560   0.37808271007017746   3.3528217500133906e-05  7.436018902737699  2.6659595732780872e-05  8.74282549825616  tensor(6.0624, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
560   0.24400213360786438
nmi:  0.7676076608461345
ari:  0.7427220422070295
alt_train_loss_clus:
570   0.3265532334521378   3.4245156712131575e-05  7.602193667523919  -1.9465053081512451  0.2599213719367981
alt_train_loss_tran:
570   0.3824042318073587   3.8391855468944414e-05  7.544585865520261  2.528336608520476e-05  8.14008961708487  tensor(6.1264, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
570   0.24192725121974945
nmi:  0.7534111559169221
ari:  0.7177564497173308
alt_train_loss_clus:
580   0.32612505272237585   4.4628914110944606e-05  7.75518050843978  -1.9463469982147217  0.2578586935997009
alt_train_loss_tran:
580   0.3690915843746083   4.5835532091587083e-05  7.715094569916658  2.3980309833859792e-05  8.560200781316825  tensor(5.8248, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
580   0.24202239513397217
nmi:  0.759288930013298
ari:  0.7319755505231427
alt_train_loss_clus:
590   0.3251002594502578   3.531945662871294e-05  7.7094037833879  -1.9463143348693848  0.25738459825515747
alt_train_loss_tran:
590   0.37985627220209145   3.195642193531967e-05  7.702932336710082  2.0469623905228218e-05  8.438619507070632  tensor(6.0461, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
590   0.24281468987464905
nmi:  0.766202443107242
ari:  0.7563811331311325
alt_train_loss_clus:
600   0.3278862494625846   4.046808498969767e-05  7.53289189196712  -1.9463365077972412  0.26188433170318604
alt_train_loss_tran:
600   0.3780441988948192   4.266894575266633e-05  7.621747310087498  1.9431186046858784e-05  8.506219694966376  tensor(6.0241, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
600   0.24367764592170715
nmi:  0.7755031770280607
ari:  0.7632075892442385
alt_train_loss_clus:
610   0.3256779526124305   4.0939698010333814e-05  7.535001376859187  -1.9463019371032715  0.2596500515937805
alt_train_loss_tran:
610   0.37180633485788056   4.297515556572762e-05  7.657507421846894  1.5572278698527953e-05  8.522431017061004  tensor(5.8929, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
610   0.24186941981315613
nmi:  0.766660266950623
ari:  0.7534168026189825
alt_train_loss_clus:
620   0.32965295499027114   4.864843845098221e-05  7.610236251686862  -1.946423053741455  0.26279622316360474
alt_train_loss_tran:
620   0.3672939724982177   3.609003988458426e-05  7.643545313642672  1.9802456790785072e-05  8.457947697895273  tensor(5.8060, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
620   0.24073171615600586
nmi:  0.7715756954605009
ari:  0.7607048018443768
alt_train_loss_clus:
630   0.32406776220534356   4.7921704663167475e-05  7.5410629338987745  -1.946169137954712  0.25790876150131226
alt_train_loss_tran:
630   0.3671725584832323   4.0422793972538784e-05  7.459605658057384  1.5114841971808346e-05  8.386676583625578  tensor(5.8404, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
630   0.24267616868019104
nmi:  0.772586520297806
ari:  0.7634199053475147
alt_train_loss_clus:
640   0.32560204355551314   5.067668257652258e-05  7.617188375744656  -1.946282148361206  0.25865480303764343
alt_train_loss_tran:
640   0.36053987747321325   5.948455691395793e-05  7.557907639669091  1.593565320945345e-05  8.822629706299963  tensor(5.6841, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
640   0.2408210039138794
nmi:  0.7800307541648803
ari:  0.7776723814910296
alt_train_loss_clus:
650   0.3237709786456553   4.858127840634552e-05  7.427883584142636  -1.9462110996246338  0.25873738527297974
alt_train_loss_tran:
650   0.3523956561845277   7.036450142550166e-05  7.588542822181047  2.0436148588487413e-05  8.486210588357626  tensor(5.5120, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
650   0.24162665009498596
nmi:  0.7720948897995725
ari:  0.778587645657473
alt_train_loss_clus:
660   0.32749553995720415   7.140213710954413e-05  7.46890481857241  -1.946195125579834  0.261823445558548
alt_train_loss_tran:
660   0.35568909722037434   6.06757428158744e-05  7.62594084616919  1.6394521480833646e-05  8.349382828014637  tensor(5.5732, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
660   0.242811918258667
nmi:  0.7716586623355347
ari:  0.7784407833795736
alt_train_loss_clus:
670   0.33108551023429367   5.972578355795122e-05  7.535858356528093  -1.9461922645568848  0.2648606300354004
alt_train_loss_tran:
670   0.3549462316513319   5.021943661631667e-05  7.492096311754095  1.6245200640696567e-05  8.462443920476474  tensor(5.5872, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
670   0.2424066662788391
nmi:  0.7697512413011656
ari:  0.7699515004461224
alt_train_loss_clus:
680   0.3281591192824893   6.678981321783795e-05  7.40203448820724  -1.9461019039154053  0.26320138573646545
alt_train_loss_tran:
680   0.3491487769970057   6.466799391091627e-05  7.4834336071923975  1.5959967640810646e-05  8.557415137933212  tensor(5.4702, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
680   0.2413063943386078
nmi:  0.7710010496316821
ari:  0.769570537579205
alt_train_loss_clus:
690   0.3261290191866497   7.835597875782696e-05  7.54830883569444  -1.9460026025772095  0.2595923840999603
alt_train_loss_tran:
690   0.34119903575649774   8.141558885199629e-05  7.424467853909704  1.462187628931133e-05  8.534706363888146  tensor(5.3199, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
690   0.23839020729064941
nmi:  0.7834498236997144
ari:  0.7649614727108206
alt_train_loss_clus:
700   0.3294234729006089   7.739124862382596e-05  7.450696497341737  -1.945963978767395  0.2638724148273468
alt_train_loss_tran:
700   0.3423845043186501   8.983636325865518e-05  7.412560259461117  1.7008168924803613e-05  8.63012251077136  tensor(5.3438, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
700   0.2400944083929062
nmi:  0.7797297977530273
ari:  0.7622651428355852
alt_train_loss_clus:
710   0.3292647413869676   5.162739398656413e-05  7.591660886430727  -1.9460773468017578  0.26256224513053894
alt_train_loss_tran:
710   0.3440840426663372   9.715824364775472e-05  7.540767522533409  1.879931915027555e-05  8.672026455503234  tensor(5.3503, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
710   0.24343723058700562
nmi:  0.7890113552737364
ari:  0.7745723613621517
alt_train_loss_clus:
720   0.3276229725356201   6.9828906703151e-05  7.561062360805536  -1.9457488059997559  0.2610428035259247
alt_train_loss_tran:
720   0.333858461986766   5.3186205150268506e-05  7.442259771402033  1.0713149094954133e-05  8.791562955543778  tensor(5.1759, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
720   0.24225524067878723
nmi:  0.7901865595812998
ari:  0.7761541420410971
alt_train_loss_clus:
730   0.330574565314188   8.011982708922005e-05  7.576645785042862  -1.945939302444458  0.2637366056442261
alt_train_loss_tran:
730   0.34171443648265426   9.762568379301229e-05  7.558326457692761  1.3871693681721808e-05  8.857855529401771  tensor(5.3003, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
730   0.2409895658493042
nmi:  0.7757043210491071
ari:  0.7546547875771303
alt_train_loss_clus:
740   0.3278929769233476   5.326158600382769e-05  7.467805055540191  -1.9458568096160889  0.26241159439086914
alt_train_loss_tran:
740   0.3252648178741179   4.7462497718697705e-05  7.50004502670304  1.094619346986292e-05  8.613603081155237  tensor(4.9936, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
740   0.23902474343776703
nmi:  0.7846828748002593
ari:  0.7710048701383454
alt_train_loss_clus:
750   0.3295522476733444   5.617525880552421e-05  7.440044383707426  -1.9458798170089722  0.26431944966316223
alt_train_loss_tran:
750   0.32934185884365175   7.563269400634454e-05  7.482131051070349  1.362356624667882e-05  8.975174626442177  tensor(5.0726, device='cuda:2', grad_fn=<AddBackward0>)
alt_train_loss_dis:
750   0.24066951870918274
nmi:  0.7866596133486166
ari:  0.7750199383157556
---------------------train finished-----------------
../dataset1/10x_PBMC/


dropout 0.3 在第一个图卷积之后
weightedfeature_mean
使用mse作为重构损失
特征判别器未一同优化
epoch 750 
seed 3407

3 clu 
1 tran

adata1 = normalize2(adata1, filter_min_counts=True, highly_genes=args.highly_genes,
                       size_factors=True, normalize_input=False,
                       logtrans_input=True)

adata2 = normalize2(adata2, filter_min_counts=True, highly_genes=args.highly_genes,
                       size_factors=True, normalize_input=False,
                       logtrans_input=True)

矩阵重构网络，最后一层激活函数sigmoid

pre_train_loss  -torch.mean(x * torch.log(torch.clamp(p, min=1e-12, max=1.0)))